{
    "name": "train",
    "n_gpu": 1,
    "preprocessing": {
        "sr": 22050
    },
    "arch": {
        "type": "HiFiGANModel",
        "args": {
            "input_channels": 80,
            "hidden_channels": 512,
            "upsample_kernels": [16, 16, 4, 4],
            "upsample_stride": [8, 8, 2, 2],
            "resblock_kernels": [3, 7, 11],
            "resblock_dilations": [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
        }
    },
    "data": {
        "train": {
            "batch_size": 100,
            "num_workers": 5,
            "datasets": [
                {
                    "type": "LJSpeechDataset",
                    "args": {
                        "part": "train"
                    }
                }
            ]
        }
    },
    "G_optimizer": {
        "type": "AdamW",
        "args": {
            "lr": 2e-4,
            "weight_decay": 0.01,
            "betas": [0.8, 0.99]
        }
    },
    "D_optimizer": {
        "type": "AdamW",
        "args": {
            "lr": 2e-4,
            "weight_decay": 0.01,
            "betas": [0.8, 0.99]
        }
    },
    "G_loss": {
        "type": "GeneratorLoss",
        "args": {
            "fm_coef": 2,
            "mel_coef": 45
        }
    },
    "D_loss": {
        "type": "DescriminatorLoss",
        "args": {}
    },
    "lr_G_scheduler": {
        "type": "ExponentialLR",
        "args": {
            "gamma": 0.999
        }
    },
    "lr_D_scheduler": {
        "type": "ExponentialLR",
        "args": {
            "gamma": 0.999
        }
    },
    "trainer": {
        "epochs": 100,
        "save_dir": "saved/",
        "save_period": 1,
        "verbosity": 2,
        "monitor": "off",
        "early_stop": 50,
        "visualize": "wandb",
        "wandb_project": "hifigan_project",
        "run_name": "train",
        "sample_rate": 22050,
        "len_epoch": 3000,
        "log_step": 50,
        "grad_norm_clip": 100000
    }
}